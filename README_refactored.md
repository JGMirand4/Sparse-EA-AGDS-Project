# SparseEA-AGDS - ImplementaÃ§Ã£o Refatorada

Uma implementaÃ§Ã£o robusta e reproduzÃ­vel do algoritmo **SparseEA-AGDS** (Sparse Evolutionary Algorithm with Adaptive Genetic Operator and Dynamic Scoring) para otimizaÃ§Ã£o multi-objetivo esparsa.

## ğŸš€ **Melhorias da VersÃ£o Refatorada**

### **1. Arquitetura Modular**
- **SeparaÃ§Ã£o de responsabilidades**: Problema, Algoritmo, ConfiguraÃ§Ã£o e MÃ©tricas
- **Interface abstrata**: FÃ¡cil adiÃ§Ã£o de novos problemas de benchmark
- **ConfiguraÃ§Ã£o externa**: ParÃ¢metros gerenciados via arquivos JSON/YAML
- **AnÃ¡lise integrada**: MÃ©tricas e testes estatÃ­sticos automatizados

### **2. Reprodutibilidade Total**
- **Controle de seeds**: Cada execuÃ§Ã£o usa seed especÃ­fica
- **ParÃ¢metros exatos**: ConfiguraÃ§Ã£o idÃªntica ao artigo original
- **CritÃ©rio de parada**: Baseado em avaliaÃ§Ãµes de funÃ§Ã£o (maxFE = 100Ã—D)
- **Testes estatÃ­sticos**: Wilcoxon rank-sum com correÃ§Ã£o para mÃºltiplas comparaÃ§Ãµes

### **3. Facilidade de Uso**
- **Script automatizado**: ExecuÃ§Ã£o de todos os experimentos com um comando
- **ExecuÃ§Ã£o paralela**: Suporte a mÃºltiplos cores para acelerar experimentos
- **Tabelas automÃ¡ticas**: GeraÃ§Ã£o de resultados em CSV, Excel e LaTeX
- **AnÃ¡lise completa**: IGD, esparsidade, testes estatÃ­sticos

## ğŸ“ **Estrutura dos Arquivos**

```
sparse-ea-agds-project/
â”œâ”€â”€ problems.py                    # Benchmarks SMOP1-SMOP8
â”œâ”€â”€ config.py                      # Sistema de configuraÃ§Ã£o
â”œâ”€â”€ metrics.py                     # MÃ©tricas de avaliaÃ§Ã£o
â”œâ”€â”€ sparse_ea_agds_refactored.py   # Algoritmo principal
â”œâ”€â”€ run_experiments.py             # Script de execuÃ§Ã£o
â”œâ”€â”€ requirements.txt               # DependÃªncias
â”œâ”€â”€ README_refactored.md           # Este arquivo
â””â”€â”€ experiment_results/            # Resultados dos experimentos
    â”œâ”€â”€ configs/                   # ConfiguraÃ§Ãµes salvas
    â”œâ”€â”€ raw_results/              # Resultados brutos
    â”œâ”€â”€ tables/                   # Tabelas resumo
    â””â”€â”€ plots/                    # GrÃ¡ficos (futuramente)
```

## âš™ï¸ **InstalaÃ§Ã£o**

```bash
# Clone o repositÃ³rio
git clone <repository-url>
cd sparse-ea-agds-project

# Instale as dependÃªncias
pip install -r requirements.txt

# Teste a instalaÃ§Ã£o
python run_experiments.py
```

## ğŸ¯ **Uso RÃ¡pido**

### **Teste RÃ¡pido**
```python
from run_experiments import ExperimentRunner

runner = ExperimentRunner()
result = runner.run_quick_test()
```

### **Experimentos Completos**
```bash
# Executa todos os benchmarks do artigo
python run_experiments.py

# Escolha opÃ§Ã£o 2 para experimentos completos
# Escolha opÃ§Ã£o 1 para teste rÃ¡pido
```

### **Uso ProgramÃ¡tico**
```python
from config import ConfigManager
from sparse_ea_agds_refactored import run_single_experiment

# Cria configuraÃ§Ã£o personalizada
config = ConfigManager.create_default_config("SMOP1", D=100, M=2)
config.algorithm.population_size = 50
config.num_runs = 10

# Executa experimento
results = run_single_experiment(config)

# Analisa resultados
print(f"IGD mÃ©dio: {results.get_metric_summary('igd').value:.4f}")
print(f"Esparsidade: {results.get_metric_summary('sparsity_percentage').value:.1f}%")
```

## ğŸ”¬ **Experimentos do Artigo**

### **ConfiguraÃ§Ã£o Exata**
Os experimentos seguem **exatamente** os parÃ¢metros do artigo:

| ParÃ¢metro | Valor |
|-----------|-------|
| PopulaÃ§Ã£o (N) | 100 |
| AvaliaÃ§Ãµes mÃ¡ximas | 100Ã—D |
| Probabilidade de crossover base (Pcâ‚€) | 1.0 |
| Probabilidade de mutaÃ§Ã£o base (Pmâ‚€) | 1/D |
| ParÃ¢metro SBX (Î·_c) | 20 |
| ParÃ¢metro mutaÃ§Ã£o (Î·_m) | 20 |
| ExecuÃ§Ãµes independentes | 30 |

### **Problemas de Benchmark**
- **SMOP1-SMOP8**: ImplementaÃ§Ã£o completa de todos os problemas
- **DimensÃµes**: 100, 500, 1000 variÃ¡veis
- **Objetivos**: 2, 3, 5, 8, 10, 15 (conforme aplicÃ¡vel)

### **MÃ©tricas de AvaliaÃ§Ã£o**
- **IGD (Inverted Generational Distance)**: Qualidade da fronteira de Pareto
- **Esparsidade**: Porcentagem de variÃ¡veis nÃ£o-zero
- **Testes estatÃ­sticos**: Wilcoxon rank-sum (p < 0.05)

## ğŸ“Š **AnÃ¡lise de Resultados**

### **Tabelas AutomÃ¡ticas**
O sistema gera automaticamente:

1. **Resumo Geral**: IGD e esparsidade por problema
2. **AnÃ¡lise por DimensÃ£o**: Desempenho vs. dimensionalidade
3. **AnÃ¡lise por Objetivos**: Desempenho vs. nÃºmero de objetivos
4. **ComparaÃ§Ã£o EstatÃ­stica**: SignificÃ¢ncia das diferenÃ§as

### **Exemplo de SaÃ­da**
```
Problem         D     M    IGD_mean    IGD_std    Sparsity_mean  Sparsity_std
SMOP1         100     2      0.0234     0.0045           15.2%       3.1%
SMOP1         500     2      0.0456     0.0078           12.8%       2.9%
SMOP1        1000     2      0.0678     0.0089           11.4%       2.5%
```

## ğŸ› ï¸ **ConfiguraÃ§Ã£o AvanÃ§ada**

### **Arquivo de ConfiguraÃ§Ã£o (JSON)**
```json
{
  "problem": {
    "name": "SMOP1",
    "dimension": 100,
    "num_objectives": 2
  },
  "algorithm": {
    "population_size": 100,
    "max_function_evaluations": 10000,
    "Pc0": 1.0,
    "Pm0": 0.01,
    "eta_c": 20.0,
    "eta_m": 20.0,
    "random_seed": 42
  },
  "num_runs": 30,
  "save_results": true,
  "verbose": true
}
```

### **CriaÃ§Ã£o de Novos Problemas**
```python
from problems import Problem

class MyProblem(Problem):
    def __init__(self, D: int, M: int):
        super().__init__(D, M)
    
    def evaluate(self, x: np.ndarray) -> np.ndarray:
        # Implementa funÃ§Ãµes objetivo
        f1 = np.sum(x**2)
        f2 = np.sum((x - 1)**2)
        return np.array([f1, f2])
    
    def get_bounds(self):
        return np.zeros(self.D), np.ones(self.D)
    
    def get_true_pareto_front(self, n_points=10000):
        # Implementa fronteira de Pareto verdadeira
        pass
```

## ğŸ”„ **ExecuÃ§Ã£o Paralela**

### **ConfiguraÃ§Ã£o de ParalelizaÃ§Ã£o**
```python
runner = ExperimentRunner()

# Executa 4 experimentos simultaneamente
results = runner.run_benchmark_experiments(
    parallel=True,
    max_workers=4
)
```

### **OtimizaÃ§Ã£o de Performance**
- **Processamento paralelo**: MÃºltiplos experimentos simultÃ¢neos
- **Gerenciamento de memÃ³ria**: Resultados salvos incrementalmente
- **Controle de recursos**: NÃºmero configurÃ¡vel de workers

## ğŸ“ˆ **ValidaÃ§Ã£o dos Resultados**

### **ComparaÃ§Ã£o com o Artigo**
Os resultados devem ser **estatisticamente equivalentes** aos do artigo original:

1. **IGD**: Valores prÃ³ximos Ã s tabelas publicadas
2. **Esparsidade**: Porcentagem de variÃ¡veis ativas similar
3. **SignificÃ¢ncia**: Testes estatÃ­sticos confirmam melhorias

### **Exemplo de ValidaÃ§Ã£o**
```python
# Carrega resultados
results = runner.load_results()

# Compara com baseline
baseline_results = load_baseline_results()  # Implementar
comparison = runner.generate_comparison_tables(results, baseline_results)

# Verifica significÃ¢ncia
significant_improvements = comparison[comparison['Statistical_Test'] == '+']
print(f"Melhorias significativas: {len(significant_improvements)}")
```

## ğŸ› **SoluÃ§Ã£o de Problemas**

### **Problemas Comuns**

1. **Erro de memÃ³ria**: Reduza `max_workers` ou `population_size`
2. **ConvergÃªncia lenta**: Verifique parÃ¢metros do algoritmo
3. **Resultados inconsistentes**: Confirme controle de seeds

### **Debug e Logging**
```python
# Ativa logging detalhado
config.verbose = True
config.log_frequency = 50  # Log a cada 50 avaliaÃ§Ãµes

# Salva populaÃ§Ãµes para anÃ¡lise
config.save_populations = True
```

## ğŸ“š **ReferÃªncias**

- **Artigo Original**: SparseEA-AGDS for Sparse Multi-objective Optimization
- **Baseline**: SparseEA (ReferÃªncia [7] no artigo)
- **Problemas**: Benchmarks SMOP1-SMOP8

## ğŸ¤ **ContribuiÃ§Ã£o**

Para contribuir com o projeto:

1. **Fork** o repositÃ³rio
2. **Crie** uma branch para sua feature
3. **Implemente** seguindo os padrÃµes do cÃ³digo
4. **Teste** com os benchmarks existentes
5. **Submeta** um pull request

## ğŸ“„ **LicenÃ§a**

Este projeto Ã© distribuÃ­do sob a licenÃ§a MIT. Veja o arquivo LICENSE para detalhes.

---

## ğŸ“ **CitaÃ§Ã£o**

Se vocÃª usar este cÃ³digo em sua pesquisa, por favor cite:

```bibtex
@article{sparseea_agds_2024,
  title={SparseEA-AGDS: ImplementaÃ§Ã£o Refatorada para OtimizaÃ§Ã£o Multi-objetivo Esparsa},
  author={Seu Nome},
  year={2024},
  url={https://github.com/seu-usuario/sparse-ea-agds}
}
```

---

**ImplementaÃ§Ã£o robusta, reproduzÃ­vel e pronta para pesquisa cientÃ­fica!** ğŸš€ 